{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Load Libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense\r\n",
    "from tensorflow import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load Dataset\r\n",
    "X = pd.read_csv('tree_class_feats.csv')\r\n",
    "Y = pd.read_csv('tree_class_target.csv')\r\n",
    "print(\"Number of records : {}\".format(len(X)))\r\n",
    "print(\"Number of features : {}\".format(X.shape[1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of records : 10000\n",
      "Number of features : 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Network\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(10, \r\n",
    "                activation = 'tanh',\r\n",
    "                input_dim = 10))\r\n",
    "model.add(Dense(5, \r\n",
    "                activation = 'tanh'))\r\n",
    "model.add(Dense(1, \r\n",
    "                activation = 'sigmoid'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy')\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "history = model.fit(X, Y, \r\n",
    "        epochs = 100,          # use 100 in actual model \r\n",
    "        batch_size = 5, \r\n",
    "        verbose = 1,\r\n",
    "        validation_split = 0.2, \r\n",
    "        shuffle = False)\r\n",
    "history.history"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.3905 - val_loss: 0.3150\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - 1s 850us/step - loss: 0.3202 - val_loss: 0.2906\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - 1s 848us/step - loss: 0.2947 - val_loss: 0.2701\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.2708 - val_loss: 0.2466\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.2478 - val_loss: 0.2246\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - 1s 847us/step - loss: 0.2284 - val_loss: 0.2084\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.2130 - val_loss: 0.1960\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.2019 - val_loss: 0.1883\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - 1s 870us/step - loss: 0.1938 - val_loss: 0.1834\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.1876 - val_loss: 0.1794\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1829 - val_loss: 0.1763\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - 1s 924us/step - loss: 0.1793 - val_loss: 0.1737\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.1765 - val_loss: 0.1716\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - 1s 866us/step - loss: 0.1743 - val_loss: 0.1700\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - 1s 874us/step - loss: 0.1724 - val_loss: 0.1686\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - 1s 875us/step - loss: 0.1709 - val_loss: 0.1676\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - 1s 865us/step - loss: 0.1695 - val_loss: 0.1666\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - 1s 829us/step - loss: 0.1683 - val_loss: 0.1659\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - 1s 846us/step - loss: 0.1672 - val_loss: 0.1652\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - 2s 995us/step - loss: 0.1662 - val_loss: 0.1646\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - 2s 947us/step - loss: 0.1652 - val_loss: 0.1641\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - 1s 885us/step - loss: 0.1644 - val_loss: 0.1637\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.1636 - val_loss: 0.1632\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - 1s 884us/step - loss: 0.1629 - val_loss: 0.1629\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - 1s 869us/step - loss: 0.1622 - val_loss: 0.1625\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - 1s 890us/step - loss: 0.1615 - val_loss: 0.1622\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.1609 - val_loss: 0.1619\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.1603 - val_loss: 0.1617\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.1597 - val_loss: 0.1614\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - 1s 885us/step - loss: 0.1591 - val_loss: 0.1612\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - 1s 847us/step - loss: 0.1586 - val_loss: 0.1609\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.1581 - val_loss: 0.1607\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.1576 - val_loss: 0.1606\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1571 - val_loss: 0.1604\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - 1s 878us/step - loss: 0.1566 - val_loss: 0.1603\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1562 - val_loss: 0.1602\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.1558 - val_loss: 0.1601\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - 1s 868us/step - loss: 0.1554 - val_loss: 0.1600\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - 1s 868us/step - loss: 0.1550 - val_loss: 0.1599\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - 1s 889us/step - loss: 0.1547 - val_loss: 0.1599\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - 1s 875us/step - loss: 0.1543 - val_loss: 0.1599\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - 1s 897us/step - loss: 0.1540 - val_loss: 0.1599\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1536 - val_loss: 0.1599\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - 1s 870us/step - loss: 0.1533 - val_loss: 0.1600\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - 1s 877us/step - loss: 0.1530 - val_loss: 0.1600\n",
      "Epoch 46/100\n",
      "1600/1600 [==============================] - 1s 887us/step - loss: 0.1527 - val_loss: 0.1599\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - 1s 886us/step - loss: 0.1523 - val_loss: 0.1599\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - 1s 898us/step - loss: 0.1521 - val_loss: 0.1597\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - 1s 895us/step - loss: 0.1518 - val_loss: 0.1596\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - 1s 919us/step - loss: 0.1515 - val_loss: 0.1595\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - 1s 901us/step - loss: 0.1513 - val_loss: 0.1593\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.1510 - val_loss: 0.1591\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - 1s 855us/step - loss: 0.1508 - val_loss: 0.1589\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.1506 - val_loss: 0.1588\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.1505 - val_loss: 0.1586\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1503 - val_loss: 0.1584\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - 1s 862us/step - loss: 0.1501 - val_loss: 0.1583\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - 1s 877us/step - loss: 0.1500 - val_loss: 0.1581\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - 1s 869us/step - loss: 0.1499 - val_loss: 0.1579\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - 1s 863us/step - loss: 0.1497 - val_loss: 0.1578\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - 1s 876us/step - loss: 0.1496 - val_loss: 0.1576\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - 1s 891us/step - loss: 0.1495 - val_loss: 0.1574\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1493 - val_loss: 0.1572\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - 1s 883us/step - loss: 0.1492 - val_loss: 0.1570\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - 1s 879us/step - loss: 0.1491 - val_loss: 0.1569\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - 2s 949us/step - loss: 0.1490 - val_loss: 0.1567\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.1488 - val_loss: 0.1565\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - 1s 841us/step - loss: 0.1487 - val_loss: 0.1563\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - 1s 857us/step - loss: 0.1486 - val_loss: 0.1561\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - 1s 834us/step - loss: 0.1484 - val_loss: 0.1559\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.1483 - val_loss: 0.1557\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - 1s 871us/step - loss: 0.1481 - val_loss: 0.1555\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - 1s 873us/step - loss: 0.1480 - val_loss: 0.1553\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - 1s 856us/step - loss: 0.1479 - val_loss: 0.1551\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - 1s 881us/step - loss: 0.1477 - val_loss: 0.1549\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - 1s 824us/step - loss: 0.1476 - val_loss: 0.1547\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - 1s 843us/step - loss: 0.1475 - val_loss: 0.1545\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.1474 - val_loss: 0.1543\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - 1s 809us/step - loss: 0.1472 - val_loss: 0.1541\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - 2s 946us/step - loss: 0.1471 - val_loss: 0.1538\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1470 - val_loss: 0.1536\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1468 - val_loss: 0.1534\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1467 - val_loss: 0.1532\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1466 - val_loss: 0.1530\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1465 - val_loss: 0.1528\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1463 - val_loss: 0.1525\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1462 - val_loss: 0.1523\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1461 - val_loss: 0.1521\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1460 - val_loss: 0.1519\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1459 - val_loss: 0.1516\n",
      "Epoch 91/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1457 - val_loss: 0.1514\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1456 - val_loss: 0.1512\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - 2s 1ms/step - loss: 0.1455 - val_loss: 0.1509\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1454 - val_loss: 0.1507\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - 3s 2ms/step - loss: 0.1453 - val_loss: 0.1505\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1451 - val_loss: 0.1502\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1450 - val_loss: 0.1500\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1449 - val_loss: 0.1498\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1448 - val_loss: 0.1496\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - 2s 2ms/step - loss: 0.1446 - val_loss: 0.1494\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [0.3905304968357086,\n",
       "  0.3202032446861267,\n",
       "  0.29472100734710693,\n",
       "  0.2708253264427185,\n",
       "  0.24777644872665405,\n",
       "  0.22840701043605804,\n",
       "  0.21301132440567017,\n",
       "  0.20192264020442963,\n",
       "  0.19379206001758575,\n",
       "  0.18764391541481018,\n",
       "  0.18293637037277222,\n",
       "  0.17931026220321655,\n",
       "  0.17650040984153748,\n",
       "  0.17426864802837372,\n",
       "  0.1724311113357544,\n",
       "  0.1708659529685974,\n",
       "  0.1694973111152649,\n",
       "  0.16827628016471863,\n",
       "  0.16717220842838287,\n",
       "  0.1661645621061325,\n",
       "  0.16523955762386322,\n",
       "  0.1643856018781662,\n",
       "  0.16359379887580872,\n",
       "  0.16285432875156403,\n",
       "  0.16215959191322327,\n",
       "  0.1615017205476761,\n",
       "  0.16087454557418823,\n",
       "  0.1602727621793747,\n",
       "  0.1596926748752594,\n",
       "  0.1591317355632782,\n",
       "  0.1585894525051117,\n",
       "  0.15806569159030914,\n",
       "  0.15756188333034515,\n",
       "  0.15708069503307343,\n",
       "  0.15662363171577454,\n",
       "  0.1561906486749649,\n",
       "  0.15578031539916992,\n",
       "  0.15539038181304932,\n",
       "  0.155018150806427,\n",
       "  0.15465986728668213,\n",
       "  0.1543111503124237,\n",
       "  0.15396808087825775,\n",
       "  0.15362955629825592,\n",
       "  0.15329693257808685,\n",
       "  0.15297195315361023,\n",
       "  0.15265509486198425,\n",
       "  0.1523480862379074,\n",
       "  0.15205369889736176,\n",
       "  0.15177437663078308,\n",
       "  0.151512011885643,\n",
       "  0.15126751363277435,\n",
       "  0.151041179895401,\n",
       "  0.15083257853984833,\n",
       "  0.15064021944999695,\n",
       "  0.15046250820159912,\n",
       "  0.15029801428318024,\n",
       "  0.15014438331127167,\n",
       "  0.14999963343143463,\n",
       "  0.14986221492290497,\n",
       "  0.14972995221614838,\n",
       "  0.14960123598575592,\n",
       "  0.14947423338890076,\n",
       "  0.14934764802455902,\n",
       "  0.14922022819519043,\n",
       "  0.1490914672613144,\n",
       "  0.1489601731300354,\n",
       "  0.1488266885280609,\n",
       "  0.1486918032169342,\n",
       "  0.14855527877807617,\n",
       "  0.14841856062412262,\n",
       "  0.14828217029571533,\n",
       "  0.14814630150794983,\n",
       "  0.14801165461540222,\n",
       "  0.14787809550762177,\n",
       "  0.1477453112602234,\n",
       "  0.14761361479759216,\n",
       "  0.14748267829418182,\n",
       "  0.147352397441864,\n",
       "  0.14722271263599396,\n",
       "  0.14709383249282837,\n",
       "  0.14696550369262695,\n",
       "  0.14683806896209717,\n",
       "  0.1467120349407196,\n",
       "  0.14658720791339874,\n",
       "  0.14646384119987488,\n",
       "  0.14634159207344055,\n",
       "  0.14622078835964203,\n",
       "  0.14610111713409424,\n",
       "  0.1459822803735733,\n",
       "  0.14586400985717773,\n",
       "  0.14574603736400604,\n",
       "  0.14562846720218658,\n",
       "  0.14551028609275818,\n",
       "  0.14539146423339844,\n",
       "  0.14527155458927155,\n",
       "  0.14514993131160736,\n",
       "  0.14502646028995514,\n",
       "  0.14490054547786713,\n",
       "  0.14477206766605377,\n",
       "  0.1446414291858673],\n",
       " 'val_loss': [0.31497251987457275,\n",
       "  0.2906234860420227,\n",
       "  0.2700980305671692,\n",
       "  0.2466164231300354,\n",
       "  0.22455240786075592,\n",
       "  0.2084140181541443,\n",
       "  0.1959923654794693,\n",
       "  0.18834662437438965,\n",
       "  0.18336401879787445,\n",
       "  0.17943227291107178,\n",
       "  0.17625391483306885,\n",
       "  0.17366820573806763,\n",
       "  0.1716064065694809,\n",
       "  0.16996486485004425,\n",
       "  0.1686427891254425,\n",
       "  0.1675563007593155,\n",
       "  0.16664524376392365,\n",
       "  0.16586901247501373,\n",
       "  0.16519992053508759,\n",
       "  0.1646176427602768,\n",
       "  0.16410614550113678,\n",
       "  0.16365240514278412,\n",
       "  0.16324575245380402,\n",
       "  0.16287733614444733,\n",
       "  0.16253991425037384,\n",
       "  0.16222767531871796,\n",
       "  0.1619352251291275,\n",
       "  0.16165903210639954,\n",
       "  0.16139765083789825,\n",
       "  0.16115286946296692,\n",
       "  0.16092833876609802,\n",
       "  0.1607283353805542,\n",
       "  0.16055530309677124,\n",
       "  0.1604081243276596,\n",
       "  0.16028235852718353,\n",
       "  0.16017219424247742,\n",
       "  0.16007401049137115,\n",
       "  0.1599884182214737,\n",
       "  0.15991945564746857,\n",
       "  0.15987512469291687,\n",
       "  0.15986327826976776,\n",
       "  0.15988442301750183,\n",
       "  0.1599244922399521,\n",
       "  0.1599590927362442,\n",
       "  0.1599661260843277,\n",
       "  0.15993238985538483,\n",
       "  0.15985631942749023,\n",
       "  0.15974459052085876,\n",
       "  0.15960703790187836,\n",
       "  0.1594519317150116,\n",
       "  0.15928621590137482,\n",
       "  0.1591152548789978,\n",
       "  0.15894244611263275,\n",
       "  0.15877020359039307,\n",
       "  0.1585993617773056,\n",
       "  0.15843018889427185,\n",
       "  0.158262237906456,\n",
       "  0.15809448063373566,\n",
       "  0.15792587399482727,\n",
       "  0.15775540471076965,\n",
       "  0.1575821042060852,\n",
       "  0.15740543603897095,\n",
       "  0.1572246104478836,\n",
       "  0.15703944861888885,\n",
       "  0.15685048699378967,\n",
       "  0.15665800869464874,\n",
       "  0.15646278858184814,\n",
       "  0.15626585483551025,\n",
       "  0.15606795251369476,\n",
       "  0.15586982667446136,\n",
       "  0.15567147731781006,\n",
       "  0.15547318756580353,\n",
       "  0.15527474880218506,\n",
       "  0.15507566928863525,\n",
       "  0.15487560629844666,\n",
       "  0.15467409789562225,\n",
       "  0.15447066724300385,\n",
       "  0.154264897108078,\n",
       "  0.15405690670013428,\n",
       "  0.153846874833107,\n",
       "  0.15363478660583496,\n",
       "  0.15342071652412415,\n",
       "  0.15320530533790588,\n",
       "  0.1529882848262787,\n",
       "  0.1527697592973709,\n",
       "  0.15254925191402435,\n",
       "  0.1523268222808838,\n",
       "  0.15210190415382385,\n",
       "  0.15187397599220276,\n",
       "  0.15164314210414886,\n",
       "  0.15140938758850098,\n",
       "  0.15117283165454865,\n",
       "  0.15093456208705902,\n",
       "  0.15069571137428284,\n",
       "  0.15045832097530365,\n",
       "  0.15022435784339905,\n",
       "  0.14999598264694214,\n",
       "  0.1497751623392105,\n",
       "  0.14956308901309967,\n",
       "  0.14935918152332306]}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Plotting training and validation loss values\r\n",
    "plt.plot(history.history['loss'])\r\n",
    "plt.plot(history.history['val_loss'])\r\n",
    "plt.title('Model loss')\r\n",
    "plt.ylabel('Model loss')\r\n",
    "plt.xlabel('Epoch')\r\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\r\n",
    "plt.show()\r\n",
    "plt.close()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "!jupyter nbconvert --to script tree_class_classification_using_keras.ipynb"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[NbConvertApp] Converting notebook tree_class_classification_using_keras.ipynb to script\n",
      "[NbConvertApp] Writing 1394 bytes to tree_class_classification_using_keras.py\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "17f877e458810ad29c05467e70789456050899caf228e00db20066c685e8045c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}